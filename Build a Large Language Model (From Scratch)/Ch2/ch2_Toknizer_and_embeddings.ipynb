{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3d5AY2GQDHV",
        "outputId": "f21c67db-8f36-4bd5-f7e0-660ccbded04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of characters 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
          ]
        }
      ],
      "source": [
        "with open('/content/the-verdict.txt','r',encoding='utf-8') as f:\n",
        "  raw_data = f.read()\n",
        "  print(\"total number of characters\",len(raw_data))\n",
        "  print(raw_data[:100])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = 'Hello, world. This, is a test. ? ?'\n",
        "result = re.split(r'([,.]|\\s)',text)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "6UUp9udWQGp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7cb26c1-5005-4b50-8c8b-add3d1ff273c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '', ' ', '?', ' ', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "c39KXOTy-FFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502ed9c0-da44-46ed-f699-561dd2a96446"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.', '?', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \" \".strip():\n",
        "  print(\"hi\")"
      ],
      "metadata": {
        "id": "q7fXuKtt3S3K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)',raw_data)\n",
        "preprocessed = [item for item in preprocessed if item.strip()]"
      ],
      "metadata": {
        "id": "2rmeKEPS4poD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhQy9K3r5nzb",
        "outputId": "fa695d6b-9056-4385-bc1c-5901ae488edc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'HAD',\n",
              " 'always',\n",
              " 'thought',\n",
              " 'Jack',\n",
              " 'Gisburn',\n",
              " 'rather',\n",
              " 'a',\n",
              " 'cheap',\n",
              " 'genius',\n",
              " '--',\n",
              " 'though',\n",
              " 'a',\n",
              " 'good',\n",
              " 'fellow',\n",
              " 'enough',\n",
              " '--',\n",
              " 'so',\n",
              " 'it',\n",
              " 'was',\n",
              " 'no',\n",
              " 'great',\n",
              " 'surprise',\n",
              " 'to',\n",
              " 'me',\n",
              " 'to',\n",
              " 'hear',\n",
              " 'that',\n",
              " ',',\n",
              " 'in']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will firstly remove duplicates by set DataStructure then Convert it to list because set return Dictinory next sort them with sort function"
      ],
      "metadata": {
        "id": "a8o6hoC_9BF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove Duplicates\n",
        "non_duplicates_words = set(preprocessed)\n",
        "#convert to list\n",
        "word_list = list(non_duplicates_words)\n",
        "#sort values\n",
        "all_words = sorted(word_list)"
      ],
      "metadata": {
        "id": "qPXnEwhD6GAE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding special tokens\n",
        "all_words.extend(['<|unk|>','<|endoftext|>'])"
      ],
      "metadata": {
        "id": "3ZMkeWnbotBg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(raw_data), len(preprocessed), len(all_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJc-jscA91n4",
        "outputId": "e1cf4f36-febf-4e33-f933-5cd8c5cb77cf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20479 4649 1161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "next doing vocabulary like Word:ID dict\n",
        "\n"
      ],
      "metadata": {
        "id": "msDjxbmtCXPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {word:idx for idx,word in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "Bzeks8Nc-A0M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx,word in enumerate(vocab.items()):\n",
        "  if idx > 10:\n",
        "    break\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw1kV3lHCxVQ",
        "outputId": "98e8c0b0-c0af-418b-cd41-5968bb13a568"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will build a simple tokenizer class with  2 features:\n",
        "1. from Words to IDs (Encoding)\n",
        "2. from IDs to Words (Decoding)   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3YgGDTEREPSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizer:\n",
        "    def __init__(self,vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_Str = {idx:words for words,idx in vocab.items()}\n",
        "    def encode(self,text):\n",
        "        preprocessed = re.split('([,.?_!\"()\\']|--|\\s)',text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        preprocessed = [\n",
        "            item if item in self.str_to_int else '<|unk|>'\n",
        "            for item in preprocessed\n",
        "        ]\n",
        "        ids  = [self.str_to_int[token] for token in preprocessed]\n",
        "        return ids\n",
        "    def decode(self,ids):\n",
        "        text = \"\".join([self.int_to_Str[idx] for idx in ids])\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text\n"
      ],
      "metadata": {
        "id": "U8NFg9RZC4t-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizer(vocab)\n",
        "\n",
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzjOtEYaoQ2a",
        "outputId": "fcb4ce9d-4d25-48f6-83a2-f443cc38bfbc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RJuNZSFpgzR",
        "outputId": "5a00ef0b-abc9-4f18-e516-b68c6c315b46"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1159,\n",
              " 5,\n",
              " 362,\n",
              " 1155,\n",
              " 642,\n",
              " 1000,\n",
              " 10,\n",
              " 1160,\n",
              " 57,\n",
              " 1013,\n",
              " 981,\n",
              " 1009,\n",
              " 738,\n",
              " 1013,\n",
              " 1159,\n",
              " 7]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "C1eIknDpplYA",
        "outputId": "4eb8779c-02a2-461e-ea6b-7146bd9ad915"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|unk|>,doyouliketea?<|endoftext|>Inthesunlitterracesofthe<|unk|>.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will use gpt2 tokenizer"
      ],
      "metadata": {
        "id": "9ItFBwqlp7IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZwZHMKnpxv3",
        "outputId": "f1a518ea-ad2b-4c7d-f3d0-57556b621de5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvMA9O_dpsvk",
        "outputId": "4eaf64f3-1050-48eb-9447-4bf5a16614c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "siRvbAZupv63"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "     \"of someunknownPlace.\"\n",
        ")\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZO0nTu5qEtN",
        "outputId": "e4186f8c-a8b2-4d10-fab1-64f0ec8dee9d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGML2Dz2qIWQ",
        "outputId": "3be5a6c9-1c79-4eaa-b000-659dbbb61f3e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IhhmYhgJqKiM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}